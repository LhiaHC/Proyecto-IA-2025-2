# üìß Clasificador de Spam y Phishing en Emails

## üìã Tabla de Contenidos

1. [Resumen del Proyecto](#resumen-del-proyecto)
2. [Instalaci√≥n y Configuraci√≥n](#instalaci√≥n-y-configuraci√≥n)
3. [Metodolog√≠a](#metodolog√≠a)
4. [Experimentaci√≥n y Resultados](#experimentaci√≥n-y-resultados)
5. [C√≥mo Ejecutar los Experimentos](#c√≥mo-ejecutar-los-experimentos)
6. [Interpretaci√≥n de Resultados](#interpretaci√≥n-de-resultados)
7. [Conclusiones](#conclusiones)
8. [Trabajos Futuros](#trabajos-futuros)
9. [Implicancias √âticas](#implicancias-√©ticas)

---

## üéØ Resumen del Proyecto

Este proyecto implementa y eval√∫a un **pipeline de Machine Learning** para clasificar emails como **spam/phishing** o **leg√≠timos**. El sistema compara sistem√°ticamente diferentes t√©cnicas de embeddings de texto (Word2Vec, FastText, BERT) con m√∫ltiples modelos de clasificaci√≥n (Regresi√≥n Log√≠stica, SVM, Random Forest) para identificar la combinaci√≥n m√°s efectiva.

### üèÜ Resultados Principales

**Mejor Modelo:** Word2Vec-300-RF
**Accuracy:** 95.82% ¬± 0.28%
**F1-Score:** 95.81% ¬± 0.28%
**Tiempo de Entrenamiento:** 0.88s

El proyecto evalu√≥ **30 configuraciones diferentes** (3 embeddings √ó 3-4 dimensiones √ó 3 clasificadores) y encontr√≥ que **Word2Vec con Random Forest supera a BERT** en este dominio espec√≠fico, siendo adem√°s 5.7x m√°s r√°pido.

### Caracter√≠sticas Principales

- **M√∫ltiples estrategias de embeddings**: Word2Vec, FastText y BERT
- **M√∫ltiples clasificadores**: Regresi√≥n Log√≠stica (LR), Support Vector Machines (SVM) y Random Forest (RF)
- **Aceleraci√≥n por GPU**: Detecci√≥n autom√°tica de GPU NVIDIA y uso de RAPIDS cuML
- **Fallback a CPU**: Uso transparente de scikit-learn cuando no hay GPU disponible
- **Cach√© de embeddings**: Los embeddings BERT se guardan en disco para evitar rec√°lculos
- **Validaci√≥n robusta**: Validaci√≥n cruzada estratificada con 5-folds
- **Experimentaci√≥n automatizada**: Scripts que ejecutan todas las combinaciones experimentales
- **Alta precisi√≥n**: Todos los modelos logran >90% de accuracy, 27 de 30 superan 92%

---

## üõ†Ô∏è Instalaci√≥n y Configuraci√≥n

### Requisitos Previos

- Python 3.11 o 3.12 (recomendado para compatibilidad de paquetes)
- Git
- (Opcional) GPU NVIDIA con CUDA para aceleraci√≥n

### Paso 1: Clonar el Repositorio

```bash
git clone https://github.com/LhiaHC/Proyecto-IA-2025-2.git
cd Proyecto-IA-2025-2
```

### Paso 2: Crear un Entorno Virtual

**En Windows:**
```bash
python -m venv iaa_venv
iaa_venv\Scripts\activate
```

**En Linux/Mac:**
```bash
python -m venv iaa_venv
source iaa_venv/bin/activate
```

### Paso 3: Instalar Dependencias

**Instalaci√≥n b√°sica (CPU):**
```bash
pip install -r requirements.txt
```

**Instalaci√≥n con aceleraci√≥n GPU (opcional):**
```bash
pip install -r requirements.txt
pip install -r requirements-gpu.txt
```

### Estructura del Proyecto

```
Proyecto-IA-2025-2/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Datos originales sin procesar
‚îÇ   ‚îú‚îÄ‚îÄ processed/              # Datos preprocesados (generado)
‚îÇ   ‚îî‚îÄ‚îÄ embeddings/             # Embeddings cacheados (generado)
‚îú‚îÄ‚îÄ reports/                    # Resultados de experimentos (generado)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ create_smaller_sample.py  # Crear muestra de datos
‚îÇ   ‚îú‚îÄ‚îÄ preprocess_data.py        # Preprocesamiento de texto
‚îÇ   ‚îú‚îÄ‚îÄ experiment_runner.py      # Ejecutor de experimentos
‚îÇ   ‚îú‚îÄ‚îÄ embeddings_03.py          # Clases de embeddings
‚îÇ   ‚îú‚îÄ‚îÄ preproc_01.py             # Funciones de preprocesamiento
‚îÇ   ‚îî‚îÄ‚îÄ utils_00.py               # Funciones utilitarias
‚îú‚îÄ‚îÄ requirements.txt            # Dependencias del proyecto
‚îî‚îÄ‚îÄ README_ES.md               # Este archivo
```

---

## üìä Metodolog√≠a

### Formulaci√≥n del Problema

**Definici√≥n Formal:**

Dado un conjunto de emails representados como texto, queremos construir una funci√≥n de clasificaci√≥n:

```
f: E ‚Üí {0, 1}
```

Donde:
- `E` es el espacio de todos los posibles emails (secuencias de texto)
- `0` representa un email leg√≠timo
- `1` representa spam/phishing

**Entrada:**
- Email en forma de texto plano: `e ‚àà E`

**Salida:**
- Etiqueta binaria: `y ‚àà {0, 1}`

### Pipeline de Procesamiento

El sistema implementa el siguiente flujo de procesamiento:

```
Email Crudo ‚Üí Preprocesamiento ‚Üí Embeddings ‚Üí Clasificador ‚Üí Predicci√≥n
```

#### 1. Preprocesamiento de Texto

El texto crudo pasa por las siguientes transformaciones:

```python
def preprocess_full(text: str) -> str:
    # 1. Conversi√≥n a min√∫sculas
    text = text.lower()

    # 2. Eliminaci√≥n de URLs
    text = re.sub(r'http\S+|www\.\S+', '', text)

    # 3. Eliminaci√≥n de emails
    text = re.sub(r'\S+@\S+', '', text)

    # 4. Eliminaci√≥n de n√∫meros
    text = re.sub(r'\d+', '', text)

    # 5. Eliminaci√≥n de puntuaci√≥n
    text = text.translate(str.maketrans('', '', string.punctuation))

    # 6. Tokenizaci√≥n
    tokens = word_tokenize(text)

    # 7. Eliminaci√≥n de stopwords
    tokens = [word for word in tokens if word not in stopwords]

    # 8. Stemming (reducci√≥n a ra√≠z)
    stemmer = PorterStemmer()
    tokens = [stemmer.stem(word) for word in tokens]

    return ' '.join(tokens)
```

**Ejemplo:**
```
Entrada: "GET YOUR FREE VIAGRA NOW! Visit http://spam.com"
Salida: "get free viagra visit"
```

#### 2. Generaci√≥n de Embeddings

Los embeddings transforman texto en vectores num√©ricos de dimensi√≥n fija. El proyecto implementa tres estrategias:

##### a) Word2Vec

**Arquitectura:** Skip-gram o CBOW (Continuous Bag of Words)

**Funcionamiento:**
- Entrena un modelo neuronal shallow de 2 capas
- Aprende representaciones vectoriales donde palabras similares tienen vectores cercanos
- Cada email se representa como el promedio de los vectores de sus palabras

```python
class Word2VecEmbedder:
    def train(self, texts: List[str]):
        tokenized = [text.split() for text in texts]
        self.model = Word2Vec(
            sentences=tokenized,
            vector_size=dim,      # Dimensi√≥n del vector (100, 200, 300)
            window=5,             # Ventana de contexto
            min_count=2,          # Frecuencia m√≠nima de palabra
            workers=CPU_CORES,    # Paralelizaci√≥n
            sg=1                  # Skip-gram (1) o CBOW (0)
        )

    def transform(self, texts: List[str]) -> np.ndarray:
        # Promedio de vectores de palabras en el vocabulario
        vectors = []
        for text in texts:
            words = [w for w in text.split() if w in self.model.wv]
            if words:
                vectors.append(np.mean([self.model.wv[w] for w in words], axis=0))
            else:
                vectors.append(np.zeros(self.vector_size))
        return np.array(vectors)
```

**Dimensiones evaluadas:** 100, 200, 300

##### b) FastText

**Arquitectura:** Similar a Word2Vec pero con subword information

**Ventaja clave:** Maneja palabras fuera del vocabulario (OOV) mediante n-gramas de caracteres

```python
class FastTextEmbedder:
    def train(self, texts: List[str]):
        tokenized = [text.split() for text in texts]
        self.model = FastText(
            sentences=tokenized,
            vector_size=dim,
            window=5,
            min_count=2,
            workers=CPU_CORES,
            sg=1,
            min_n=3,              # n-grama m√≠nimo
            max_n=6               # n-grama m√°ximo
        )
```

**Ejemplo:**
- Palabra: "running"
- N-gramas (n=3): "run", "unn", "nni", "nin", "ing"
- Vector final = combinaci√≥n de n-gramas

**Dimensiones evaluadas:** 100, 200, 300

##### c) BERT (Bidirectional Encoder Representations from Transformers)

**Arquitectura:** Transformer pre-entrenado

**Modelo usado:** `bert-base-uncased` (110M par√°metros)

**Caracter√≠sticas:**
- Embeddings contextuales: la representaci√≥n de una palabra depende del contexto completo
- Pre-entrenado en grandes corpus (Wikipedia + BookCorpus)
- Se usa el pooling del token [CLS] como representaci√≥n del email completo

```python
class BERTEmbedder:
    def __init__(self):
        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
        self.model = BertModel.from_pretrained('bert-base-uncased')
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        self.model.eval()

    def transform(self, texts: List[str]) -> np.ndarray:
        embeddings = []
        for text in texts:
            # Tokenizaci√≥n
            inputs = self.tokenizer(
                text,
                padding=True,
                truncation=True,
                max_length=512,
                return_tensors='pt'
            ).to(self.device)

            # Forward pass sin gradientes
            with torch.no_grad():
                outputs = self.model(**inputs)

            # Pooling del token [CLS]
            cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()
            embeddings.append(cls_embedding[0])

        return np.array(embeddings)
```

**Dimensi√≥n original:** 768

**Reducci√≥n dimensional:** Opcionalmente se aplica PCA para reducir a 100, 200 o 300 dimensiones

**Cach√© de embeddings:**

Los embeddings BERT son costosos de calcular. Para optimizar:
- **Primera ejecuci√≥n:** Se calculan y guardan en `data/embeddings/bert_{dim}.npy`
- **Ejecuciones posteriores:** Se cargan del disco, reduciendo tiempo de horas a minutos

#### 3. Clasificadores

Se eval√∫an tres algoritmos de clasificaci√≥n:

##### a) Regresi√≥n Log√≠stica (LR)

**Funci√≥n de decisi√≥n:**
```
P(y=1|x) = œÉ(w^T x + b)
donde œÉ(z) = 1 / (1 + e^(-z))
```

**Optimizaci√≥n:** Descenso de gradiente con regularizaci√≥n L2

**Hiperpar√°metros:**
- `max_iter=2000`: Iteraciones m√°ximas
- `C=1.0`: Inverso de la fuerza de regularizaci√≥n

##### b) Support Vector Machine (SVM)

**Funci√≥n de decisi√≥n:**
```
f(x) = sign(w^T x + b)
```

**Objetivo:** Maximizar el margen entre clases

**Kernel:** Linear (para alta dimensionalidad)

**Hiperpar√°metros:**
- `kernel='linear'`
- `C=1.0`: Par√°metro de penalizaci√≥n

##### c) Random Forest (RF)

**Ensemble de √°rboles de decisi√≥n**

**Proceso:**
1. Bootstrap sampling (muestreo con reemplazo)
2. Entrenar N √°rboles de decisi√≥n
3. Votaci√≥n mayoritaria para predicci√≥n

**Hiperpar√°metros:**
- `n_estimators=100`: N√∫mero de √°rboles
- `max_depth=None`: Profundidad ilimitada
- Criterio de divisi√≥n: Gini impurity

#### 4. Validaci√≥n Cruzada Estratificada

**M√©todo:** Stratified K-Fold Cross-Validation (k=5)

**Proceso:**
```
Para cada fold i = 1..k:
    1. Dividir datos en 80% train, 20% test (preservando distribuci√≥n de clases)
    2. Entrenar embedder (Word2Vec/FastText) o cargar embeddings (BERT)
    3. Generar representaciones vectoriales
    4. Entrenar clasificador
    5. Evaluar en conjunto de test
    6. Guardar m√©tricas

Retornar: media ¬± desviaci√≥n est√°ndar de todas las m√©tricas
```

**Ventaja de estratificaci√≥n:** Garantiza que cada fold tenga la misma proporci√≥n de spam/leg√≠timo que el dataset completo.

### Aceleraci√≥n por GPU

**Detecci√≥n autom√°tica:**
```python
try:
    import cupy as cp
    from cuml.linear_model import LogisticRegression as cuLR

    if torch.cuda.is_available():
        use_gpu = True
    else:
        use_gpu = False
except ImportError:
    use_gpu = False
```

**Beneficios:**
- LR en GPU: ~10-50x m√°s r√°pido
- SVM en GPU: ~5-20x m√°s r√°pido
- RF en GPU: ~3-10x m√°s r√°pido

---

## üß™ Experimentaci√≥n y Resultados

### Setup Experimental

#### Datos Utilizados

**Dataset:** Emails del corpus Enron + emails de phishing sint√©ticos

**Caracter√≠sticas:**
- **Tama√±o original:** Variable (depende del archivo en `data/raw/`)
- **Muestra utilizada:** 2,500 emails (para experimentaci√≥n r√°pida)
- **Distribuci√≥n de clases:**
  - Leg√≠timo (0): ~50%
  - Spam/Phishing (1): ~50%

**Preprocesamiento aplicado:**
- Limpieza de URLs, emails, n√∫meros
- Normalizaci√≥n a min√∫sculas
- Eliminaci√≥n de stopwords
- Stemming

**Formato de almacenamiento:** Parquet (comprimido y eficiente)

#### M√©tricas de Evaluaci√≥n

Se eval√∫an 5 m√©tricas principales:

##### 1. Accuracy (Exactitud)
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```
Proporci√≥n de predicciones correctas sobre el total.

##### 2. Precision (Precisi√≥n)
```
Precision = TP / (TP + FP)
```
De todos los emails clasificados como spam, ¬øcu√°ntos realmente lo son?

**Interpretaci√≥n:** Alta precision = pocos falsos positivos (emails leg√≠timos marcados como spam)

##### 3. Recall (Sensibilidad)
```
Recall = TP / (TP + FN)
```
De todos los emails que son spam, ¬øcu√°ntos se detectaron?

**Interpretaci√≥n:** Alto recall = pocos falsos negativos (spam que pasa como leg√≠timo)

##### 4. F1-Score
```
F1 = 2 √ó (Precision √ó Recall) / (Precision + Recall)
```
Media arm√≥nica entre precision y recall.

**Interpretaci√≥n:** Balance entre precision y recall. M√©trica clave cuando las clases est√°n balanceadas.

##### 5. Fit Time (Tiempo de Entrenamiento)
Tiempo en segundos que tarda en entrenar el modelo.

**Todas las m√©tricas se reportan con:**
- **Media (mean):** Promedio sobre los k-folds
- **Desviaci√≥n est√°ndar (std):** Variabilidad entre folds

### Dise√±o Experimental

Se eval√∫an **todas las combinaciones** de:

| Componente | Opciones | Total |
|------------|----------|-------|
| **Embeddings** | Word2Vec, FastText, BERT | 3 |
| **Dimensionalidad** | 100, 200, 300, 768* | 4 |
| **Clasificadores** | LR, SVM, RF | 3 |

*768 solo para BERT (dimensi√≥n nativa)

**Total de experimentos:**
- Word2Vec: 3 dimensiones √ó 3 clasificadores = 9 experimentos
- FastText: 3 dimensiones √ó 3 clasificadores = 9 experimentos
- BERT: 4 dimensiones √ó 3 clasificadores = 12 experimentos
- **TOTAL: 30 experimentos**

### Estrategia de Validaci√≥n

**M√©todo:** 5-Fold Stratified Cross-Validation

**Justificaci√≥n:**
- K=5 es un balance entre varianza (k peque√±o) y bias (k grande)
- Estratificaci√≥n asegura representatividad en cada fold
- Permite evaluar robustez del modelo ante diferentes splits

---

## üöÄ C√≥mo Ejecutar los Experimentos

### Flujo Completo de Ejecuci√≥n

#### Paso 1: Crear Muestra de Datos

```bash
python src\create_smaller_sample.py
```

**Qu√© hace:**
- Lee el dataset original en `data/raw/`
- Crea una muestra estratificada de 2,500 emails
- Guarda en `data/processed/email_sample.csv`

**Tiempo estimado:** 5-10 segundos

#### Paso 2: Preprocesar los Datos

```bash
python src\preprocess_data.py
```

**Qu√© hace:**
- Lee la muestra creada en el paso anterior
- Aplica todas las transformaciones de texto (limpieza, tokenizaci√≥n, stemming)
- Guarda datos limpios en `data/processed/preprocessed_emails_sample.parquet`

**Tiempo estimado:** 30-60 segundos (usa paralelizaci√≥n con pandarallel)

**Salida:**
```
INFO: Pandarallel will run on 8 workers.
100.00% :::::::::::::::::::: | 2500 / 2500 |
Guardando el archivo final listo para los experimentos...
Preprocesamiento completado.
```

#### Paso 3: Ejecutar Experimentos Individuales

**Sintaxis:**
```bash
python src\experiment_runner.py --embedding <TIPO> --dim <DIM> --classifier <CLF>
```

**Par√°metros:**
- `--embedding`: `word2vec`, `fasttext`, o `bert`
- `--dim`: `100`, `200`, `300` (Word2Vec/FastText) o `100`, `200`, `300`, `768` (BERT)
- `--classifier`: `lr` (Logistic Regression), `svm`, o `rf` (Random Forest)
- `--k_folds`: (opcional) N√∫mero de folds, default=5

**Ejemplos:**

```bash
# Word2Vec con 100 dimensiones + Logistic Regression
python src\experiment_runner.py --embedding word2vec --dim 100 --classifier lr

# FastText con 200 dimensiones + SVM
python src\experiment_runner.py --embedding fasttext --dim 200 --classifier svm

# BERT con 768 dimensiones + Random Forest
python src\experiment_runner.py --embedding bert --dim 768 --classifier rf

# BERT con PCA a 300 dimensiones + Logistic Regression
python src\experiment_runner.py --embedding bert --dim 300 --classifier lr
```

**Tiempo estimado por experimento:**
- Word2Vec/FastText: 1-5 minutos (CPU) / 30s-2min (GPU)
- BERT (primera vez): 10-30 minutos (genera y cachea embeddings)
- BERT (con cach√©): 1-5 minutos (CPU) / 30s-2min (GPU)

**Salida de ejemplo:**
```
cuML no encontrado. Usando scikit-learn en CPU.

--- Experimento: WORD2VEC (dim=100) + LR ---

Cargando datos preprocesados...
Total de emails: 2500

Iniciando CV con re-entrenamiento para WORD2VEC...
--- Fold 1/5 ---
Entrenando Word2Vec...
--- Fold 2/5 ---
Entrenando Word2Vec...
...
--- Fold 5/5 ---
Entrenando Word2Vec...

========================================
Resultados Finales (5-fold CV)
========================================
ACCURACY  : 0.9245 ¬± 0.0123
PRECISION : 0.9198 ¬± 0.0156
RECALL    : 0.9287 ¬± 0.0145
F1        : 0.9241 ¬± 0.0128
FIT_TIME  : 2.3456 ¬± 0.2341

Guardando resultados en 'reports/results_word2vec_100_lr.csv'...
```

#### Paso 4: Ejecutar TODOS los Experimentos

**En Linux/Mac con Bash:**
```bash
chmod +x run_all_experiments.sh
./run_all_experiments.sh
```

**En Windows (PowerShell):**

Crea un archivo `run_all_experiments.ps1`:

```powershell
# Definir arrays de par√°metros
$embeddings = @("word2vec", "fasttext", "bert")
$dims_regular = @(100, 200, 300)
$dims_bert = @(100, 200, 300, 768)
$classifiers = @("lr", "svm", "rf")

# Ejecutar experimentos para Word2Vec y FastText
foreach ($emb in @("word2vec", "fasttext")) {
    foreach ($dim in $dims_regular) {
        foreach ($clf in $classifiers) {
            Write-Host "`n========================================" -ForegroundColor Cyan
            Write-Host "Experimento: $emb (dim=$dim) + $clf" -ForegroundColor Cyan
            Write-Host "========================================`n" -ForegroundColor Cyan

            python src\experiment_runner.py --embedding $emb --dim $dim --classifier $clf

            if ($LASTEXITCODE -ne 0) {
                Write-Host "Error en experimento: $emb-$dim-$clf" -ForegroundColor Red
            }
        }
    }
}

# Ejecutar experimentos para BERT
foreach ($dim in $dims_bert) {
    foreach ($clf in $classifiers) {
        Write-Host "`n========================================" -ForegroundColor Cyan
        Write-Host "Experimento: BERT (dim=$dim) + $clf" -ForegroundColor Cyan
        Write-Host "========================================`n" -ForegroundColor Cyan

        python src\experiment_runner.py --embedding bert --dim $dim --classifier $clf

        if ($LASTEXITCODE -ne 0) {
            Write-Host "Error en experimento: bert-$dim-$clf" -ForegroundColor Red
        }
    }
}

Write-Host "`n========================================" -ForegroundColor Green
Write-Host "Todos los experimentos completados" -ForegroundColor Green
Write-Host "Resultados guardados en reports/" -ForegroundColor Green
Write-Host "========================================`n" -ForegroundColor Green
```

Luego ejecutar:
```powershell
.\run_all_experiments.ps1
```

**Tiempo total estimado:**
- Con CPU: 2-4 horas
- Con GPU: 30-60 minutos

---

## üìà Interpretaci√≥n de Resultados

### Archivos de Salida

Cada experimento genera un archivo CSV en `reports/`:

**Nombre:** `results_{embedding}_{dim}_{classifier}.csv`

**Ejemplo:** `results_bert_768_lr.csv`

**Columnas del archivo:**

| Columna | Descripci√≥n | Ejemplo |
|---------|-------------|---------|
| `embedding` | Tipo de embedding usado | `bert` |
| `dimensionality` | Dimensi√≥n de vectores | `768` |
| `pca_applied` | ¬øSe aplic√≥ PCA? | `no` |
| `classifier` | Clasificador usado | `lr` |
| `k_folds` | N√∫mero de folds | `5` |
| `cv_accuracy_mean` | Accuracy promedio | `0.9523` |
| `cv_accuracy_std` | Desv. est√°ndar accuracy | `0.0087` |
| `cv_precision_mean` | Precision promedio | `0.9481` |
| `cv_precision_std` | Desv. est√°ndar precision | `0.0102` |
| `cv_recall_mean` | Recall promedio | `0.9567` |
| `cv_recall_std` | Desv. est√°ndar recall | `0.0095` |
| `cv_f1_mean` | F1-score promedio | `0.9523` |
| `cv_f1_std` | Desv. est√°ndar F1 | `0.0089` |
| `cv_fit_time_mean` | Tiempo entren. promedio (s) | `2.341` |
| `cv_fit_time_std` | Desv. est√°ndar tiempo | `0.234` |

### An√°lisis de Resultados

#### 1. Comparar Embeddings

**Pregunta:** ¬øQu√© t√©cnica de embedding funciona mejor?

**An√°lisis:**
```python
import pandas as pd
import matplotlib.pyplot as plt

# Cargar todos los resultados
results = []
for file in os.listdir('reports/'):
    if file.endswith('.csv'):
        df = pd.read_csv(f'reports/{file}')
        results.append(df)

all_results = pd.concat(results, ignore_index=True)

# Agrupar por embedding
embedding_comparison = all_results.groupby('embedding').agg({
    'cv_f1_mean': ['mean', 'max'],
    'cv_accuracy_mean': ['mean', 'max']
})

print(embedding_comparison)
```

**Interpretaci√≥n esperada:**
- **BERT** deber√≠a tener el mejor F1 promedio (embeddings contextuales)
- **FastText** deber√≠a superar a **Word2Vec** (maneja OOV)
- **Word2Vec** es el m√°s r√°pido de entrenar

#### 2. Comparar Clasificadores

**Pregunta:** ¬øQu√© clasificador funciona mejor?

```python
classifier_comparison = all_results.groupby('classifier').agg({
    'cv_f1_mean': ['mean', 'std'],
    'cv_fit_time_mean': 'mean'
})
```

**Interpretaci√≥n esperada:**
- **SVM** puede tener el mejor F1 (bueno para alta dimensionalidad)
- **Random Forest** puede ser m√°s robusto (menor std)
- **Logistic Regression** es el m√°s r√°pido

#### 3. Efecto de la Dimensionalidad

**Pregunta:** ¬øM√°s dimensiones = mejor performance?

```python
dim_effect = all_results.groupby(['embedding', 'dimensionality']).agg({
    'cv_f1_mean': 'mean'
}).reset_index()

for emb in ['word2vec', 'fasttext', 'bert']:
    subset = dim_effect[dim_effect['embedding'] == emb]
    plt.plot(subset['dimensionality'], subset['cv_f1_mean'], marker='o', label=emb)

plt.xlabel('Dimensionalidad')
plt.ylabel('F1-Score Promedio')
plt.legend()
plt.show()
```

**Interpretaci√≥n esperada:**
- Relaci√≥n no lineal: 200-300 dims suelen ser √≥ptimas
- 768 dims (BERT nativo) puede tener overfitting en datasets peque√±os
- PCA a 300 puede mejorar generalizaci√≥n

#### 4. Trade-off Performance vs. Tiempo

**Pregunta:** ¬øCu√°l es el mejor balance accuracy/tiempo?

```python
plt.scatter(all_results['cv_fit_time_mean'], all_results['cv_f1_mean'],
            c=all_results['embedding'].astype('category').cat.codes)
plt.xlabel('Tiempo de Entrenamiento (s)')
plt.ylabel('F1-Score')
plt.colorbar(label='Embedding Type')
plt.show()
```

### M√©tricas Clave a Reportar

Para el informe acad√©mico, reporta:

1. **Mejor configuraci√≥n general:**
   - Embedding + Dim + Classifier con mayor F1
   - Reportar: F1, Accuracy, Precision, Recall con ¬± std

2. **Mejor configuraci√≥n por embedding:**
   - **Mejor Word2Vec:** Word2Vec-300-RF (F1=0.9581, Accuracy=95.82%, Tiempo=0.88s)
   - **Mejor FastText:** FastText-300-RF (F1=0.9469, Accuracy=94.70%, Tiempo=0.89s)
   - **Mejor BERT:** BERT-768-LR (F1=0.9455, Accuracy=94.56%, Tiempo=5.05s)

3. **Tabla comparativa TOP 10 (Resultados Completos - 30 Experimentos):**

| Ranking | M√©todo | Accuracy | Precision | Recall | F1 | Tiempo (s) |
|---------|--------|----------|-----------|--------|-----|------------|
| ü•á 1 | Word2Vec-300-RF | **0.9582¬±0.0028** | **0.9584¬±0.0029** | **0.9579¬±0.0027** | **0.9581¬±0.0028** | 0.88¬±0.02 |
| ü•à 2 | Word2Vec-200-RF | 0.9572¬±0.0029 | 0.9573¬±0.0030 | 0.9570¬±0.0029 | 0.9571¬±0.0029 | **0.72¬±0.02** |
| ü•â 3 | Word2Vec-100-RF | 0.9554¬±0.0026 | 0.9555¬±0.0027 | 0.9551¬±0.0025 | 0.9553¬±0.0026 | **0.18¬±0.03** |
| 4 | FastText-300-RF | 0.9470¬±0.0072 | 0.9475¬±0.0069 | 0.9465¬±0.0073 | 0.9469¬±0.0072 | 0.89¬±0.01 |
| 5 | FastText-200-RF | 0.9462¬±0.0030 | 0.9469¬±0.0028 | 0.9456¬±0.0031 | 0.9460¬±0.0030 | 0.42¬±0.01 |
| 6 | BERT-768-LR | 0.9456¬±0.0054 | 0.9459¬±0.0052 | 0.9453¬±0.0056 | 0.9455¬±0.0055 | 5.05¬±0.63 |
| 7 | FastText-100-RF | 0.9446¬±0.0027 | 0.9449¬±0.0026 | 0.9442¬±0.0027 | 0.9444¬±0.0027 | 0.32¬±0.01 |
| 8 | BERT-768-SVM | 0.9420¬±0.0064 | 0.9423¬±0.0062 | 0.9417¬±0.0066 | 0.9419¬±0.0065 | 3.60¬±0.13 |
| 9 | Word2Vec-200-SVM | 0.9412¬±0.0048 | 0.9418¬±0.0047 | 0.9406¬±0.0049 | 0.9410¬±0.0048 | 1.43¬±0.01 |
| 10 | BERT-300-LR | 0.9404¬±0.0043 | 0.9407¬±0.0042 | 0.9400¬±0.0045 | 0.9403¬±0.0043 | 2.67¬±0.11 |

4. **An√°lisis Detallado por Componente:**

**Por Embedding:**
| Embedding | Experimentos | Mejor Config | Mejor F1 | Peor F1 | Promedio F1 | Promedio Tiempo |
|-----------|--------------|--------------|----------|---------|-------------|-----------------|
| Word2Vec | 9 | 300-RF | 0.9581 | 0.9324 | **0.9432** | 1.54s |
| FastText | 9 | 300-RF | 0.9469 | 0.9232 | 0.9331 | 1.48s |
| BERT | 12 | 768-LR | 0.9455 | 0.9029 | 0.9282 | 1.89s |

**Por Clasificador:**
| Clasificador | Experimentos | Mejor Config | Mejor F1 | Promedio F1 | Promedio Tiempo |
|--------------|--------------|--------------|----------|-------------|-----------------|
| Random Forest | 10 | Word2Vec-300-RF | **0.9581** | **0.9363** | **0.57s** |
| SVM | 10 | BERT-768-SVM | 0.9419 | 0.9337 | 1.41s |
| Logistic Regression | 10 | BERT-768-LR | 0.9455 | 0.9325 | 3.01s |

**Insights Clave:**
- **Random Forest domina:** 6 de los TOP 10 modelos usan RF
- **Word2Vec es el mejor embedding:** Promedio F1=0.9432 vs FastText=0.9331 y BERT=0.9282
- **RF es el clasificador m√°s r√°pido:** 0.57s promedio vs SVM=1.41s y LR=3.01s
- **Mejor trade-off velocidad/performance:** Word2Vec-100-RF (F1=0.9553 en solo 0.18s)
- **Modelos con F1 > 0.95:** 3 (todos Word2Vec-RF)
- **Modelos con F1 > 0.94:** 10 modelos
- **Modelos con F1 > 0.92:** 27 de 30 modelos (90%)

---

## üí° Conclusiones

### Hallazgos Principales

Basado en los **30 experimentos completos** (3 embeddings √ó 3-4 dimensiones √ó 3 clasificadores), las conclusiones son:

1. **Performance de Embeddings:**
   - **Word2Vec** logra sorprendentemente el mejor desempe√±o general (F1=0.9581 con RF-300) superando incluso a BERT
   - **Random Forest** domina consistentemente: 6 de los TOP 10 modelos usan RF
   - **BERT** (F1=0.9455 con LR-768) tiene buen desempe√±o pero es 5.7x m√°s lento que Word2Vec-300-RF
   - **FastText** (F1=0.9469 con RF-300) queda en medio, ligeramente por debajo de Word2Vec
   - **Word2Vec-RF** ocupa los primeros 3 lugares del ranking completo

2. **Respuesta a Hip√≥tesis:**

   **Hip√≥tesis 1:** *"Los embeddings pre-entrenados (BERT) superar√°n a los embeddings entrenados desde cero (Word2Vec/FastText)"*

   ‚ùå **RECHAZADA:** Word2Vec-RF supera a BERT por +1.26 puntos de F1 (0.9581 vs 0.9455). Los embeddings espec√≠ficos del dominio entrenados sobre el corpus de spam/phishing funcionan mejor que embeddings gen√©ricos pre-entrenados para esta tarea especializada.

   **Hip√≥tesis 2:** *"SVM tendr√° mejor desempe√±o que LR y RF en espacios de alta dimensionalidad"*

   ‚ùå **RECHAZADA:** Random Forest domina completamente. De los TOP 10 modelos, 7 son RF. El mejor SVM (BERT-768-SVM, ranking #8) alcanza F1=0.9419, mientras el mejor RF (Word2Vec-300-RF) alcanza F1=0.9581.

3. **Eficiencia:**
   - **Word2Vec-100-RF** ofrece el mejor trade-off velocidad/performance: F1=0.9553 en solo **0.18s** (ranking #3)
   - **Word2Vec-200-RF** balance √≥ptimo: F1=0.9571 en 0.72s (ranking #2)
   - **BERT** es significativamente m√°s lento: 2.59-5.05s vs 0.18-0.89s
   - El **cach√© de embeddings BERT** reduce tiempo de re-experimentaci√≥n de horas a segundos
   - Dimensionalidad √≥ptima: **200-300** (300 da el mejor F1, pero 200 es m√°s r√°pido con F1 casi id√©ntico)

4. **Robustez:**
   - Desviaciones est√°ndar muy bajas (0.0026-0.0078) indican alta estabilidad
   - Validaci√≥n cruzada estratificada garantiza generalizaci√≥n
   - **Todos los modelos logran Accuracy > 0.90** (90%)
   - **27 de 30 modelos logran F1 > 0.92** (92%)

### ¬øEl enfoque resuelve siempre el problema?

**S√ç, con muy alta confiabilidad:**
- Accuracy m√≠nima observada: **90.30%** (BERT-300-RF)
- Accuracy m√°xima observada: **95.82%** (Word2Vec-300-RF)
- **Todos los 30 modelos logran Accuracy > 90%**
- **27 de 30 modelos logran F1 > 0.92** (92%)
- Recall > 0.90 en TODAS las configuraciones (cr√≠tico para detectar spam)
- Los TOP 10 modelos superan 94% de accuracy

**Limitaciones:**
- Performance puede degradarse con emails muy cortos (< 10 palabras)
- Phishing sofisticado que imita lenguaje leg√≠timo puede evadir detecci√≥n
- Requiere re-entrenamiento peri√≥dico para adaptarse a nuevos patrones de spam
- Word2Vec/FastText necesitan vocabulario suficiente para entrenar (m√≠nimo ~1000 emails)
- BERT-RF tiene el peor desempe√±o (F1=0.9029-0.9203) posiblemente por overfitting en alta dimensionalidad

### Comparaci√≥n con Baseline

**Baseline hipot√©tico:** Clasificador de Bayes Ingenuo con TF-IDF (~89% accuracy reportado en literatura)

| M√©trica | Baseline (NB + TF-IDF) | Mejor Modelo (Word2Vec-300-RF) | Mejora |
|---------|------------------------|-------------------------------|--------|
| Accuracy | ~0.89 | **0.9582** | +7.6% |
| F1-Score | ~0.88 | **0.9581** | +8.9% |
| Precision | ~0.87 | **0.9584** | +10.2% |
| Recall | ~0.89 | **0.9579** | +7.6% |
| Tiempo | ~0.5s | 0.88s | -1.8x |

**Conclusi√≥n:** El enfoque propuesto supera significativamente al baseline tradicional con un incremento m√≠nimo en tiempo de entrenamiento.

---

## üîÆ Trabajos Futuros

### Mejoras del Enfoque

1. **Arquitecturas m√°s avanzadas:**
   - Implementar fine-tuning completo de BERT (no solo usar embeddings congelados)
   - Evaluar modelos m√°s recientes: RoBERTa, DistilBERT, ELECTRA
   - Probar GPT embeddings para capturar patrones generativos de spam

2. **Ensemble learning:**
   - Combinar predicciones de m√∫ltiples embeddings (voting/stacking)
   - Implementar boosting (XGBoost, LightGBM) sobre embeddings

3. **Feature engineering:**
   - A√±adir features metadatos: longitud de email, cantidad de URLs, presencia de keywords
   - Incorporar an√°lisis de estructura HTML (para phishing web-based)
   - Extraer features de headers de email (remitente, hora, etc.)

4. **Optimizaci√≥n de hiperpar√°metros:**
   - Grid search o Bayesian optimization para C (SVM), max_depth (RF), etc.
   - Auto-tuning de dimensionalidad de embeddings

5. **Datos y escalabilidad:**
   - Evaluar en datasets m√°s grandes (> 100K emails)
   - Implementar online learning para adaptaci√≥n continua
   - Probar con emails multiidioma

### Otros Problemas Abordables

El pipeline desarrollado es generalizable a:

1. **Clasificaci√≥n de sentimientos** (producto reviews, tweets)
2. **Categorizaci√≥n de noticias** (pol√≠tica, deportes, tecnolog√≠a)
3. **Detecci√≥n de fake news**
4. **Clasificaci√≥n de intenci√≥n en chatbots**
5. **An√°lisis de riesgo en comentarios** (toxicidad, hate speech)

**Requerimientos:** Cambiar el dataset y ajustar el n√∫mero de clases en el clasificador.

---

## ‚öñÔ∏è Implicancias √âticas

### Riesgos Potenciales

#### 1. Sesgos en el Dataset

**Problema:**
- Si el dataset contiene m√°s spam de ciertos idiomas/culturas, el modelo puede discriminar emails leg√≠timos de esas poblaciones
- Emails de marketing leg√≠timo de ciertas industrias pueden ser incorrectamente clasificados como spam

**Ejemplo:**
- Dataset entrenado primariamente en ingl√©s puede clasificar emails en espa√±ol como spam
- Emails promocionales de peque√±os negocios pueden ser penalizados vs. grandes corporaciones

**Mitigaci√≥n:**
- Auditor√≠a de dataset para balance demogr√°fico/ling√º√≠stico
- Evaluaci√≥n de fairness por subgrupos (an√°lisis de disparity)
- Incluir ejemplos diversos en entrenamiento

#### 2. Falsos Positivos (Emails Leg√≠timos como Spam)

**Impacto:**
- P√©rdida de comunicaciones importantes (ofertas de trabajo, notificaciones m√©dicas)
- Da√±o econ√≥mico (emails de clientes/proveedores no recibidos)

**Mitigaci√≥n:**
- Priorizar **alta recall** (detectar todo el spam) sobre precision cuando sea cr√≠tico
- Implementar folder de "cuarentena" en vez de eliminaci√≥n directa
- Permitir whitelist de remitentes confiables
- Interfaz de "reportar falso positivo" con re-entrenamiento incremental

#### 3. Evasi√≥n Adversarial

**Riesgo:**
- Spammers pueden dise√±ar emails adversariales que evadan el filtro
- T√©cnicas: agregar ruido imperceptible, sin√≥nimos, codificaci√≥n de caracteres

**Ejemplo:**
- "F R E E   V I A G R A" (espacios) puede evadir detector entrenado en "FREE VIAGRA"

**Mitigaci√≥n:**
- Re-entrenamiento frecuente con nuevos ejemplos de spam
- Adversarial training (entrenar con ejemplos adversariales sint√©ticos)
- Ensemble de m√∫ltiples modelos (m√°s dif√≠cil evadir todos)

#### 4. Privacidad

**Problema:**
- El modelo necesita acceder al contenido completo de emails para clasificar
- Riesgo de exposici√≥n de informaci√≥n sensible si el sistema es comprometido

**Mitigaci√≥n:**
- Procesamiento on-device (modelo en el cliente, no servidor)
- Anonimizaci√≥n de datos de entrenamiento (eliminar nombres, direcciones, etc.)
- Encriptaci√≥n de embeddings en tr√°nsito y reposo
- Auditor√≠as de seguridad peri√≥dicas

#### 5. Transparencia y Explicabilidad

**Problema:**
- BERT es un modelo de "caja negra" dif√≠cil de interpretar
- Usuarios no entienden por qu√© su email fue clasificado como spam

**Mitigaci√≥n:**
- Implementar LIME/SHAP para explicar predicciones individuales
- Mostrar palabras/frases que m√°s contribuyeron a la clasificaci√≥n
- Proveer opci√≥n de "¬øPor qu√© fue marcado como spam?" con explicaci√≥n textual

#### 6. Uso Dual (Dual-Use)

**Riesgo:**
- La misma tecnolog√≠a para detectar spam puede usarse para censura
- Gobiernos autoritarios podr√≠an filtrar comunicaciones pol√≠ticas leg√≠timas

**Consideraci√≥n:**
- Documentar claramente el uso √©tico pretendido
- Evitar venta/licenciamiento a entidades con historial de abuso
- Open-source con licencias que proh√≠ban uso para censura

### Marco √âtico de Implementaci√≥n

Si este sistema fuera escalado a producci√≥n, se recomienda:

1. **Comit√© de √âtica:**
   - Revisi√≥n trimestral de sesgos y fairness
   - Evaluaci√≥n de impacto social

2. **Transparencia:**
   - Publicar tasa de falsos positivos/negativos
   - Documentar proceso de apelaci√≥n para usuarios

3. **Consentimiento:**
   - Informar a usuarios que se usa ML para filtrar emails
   - Opci√≥n de opt-out (desactivar filtro autom√°tico)

4. **Auditor√≠a:**
   - Logs de decisiones (qu√© emails fueron filtrados)
   - An√°lisis de patrones de error por demograf√≠a

5. **Responsabilidad:**
   - Designar responsable legal de decisiones del sistema
   - Seguro contra da√±os causados por falsos positivos cr√≠ticos

---

## üìö Referencias

1. **Word2Vec:**
   - Mikolov, T., et al. (2013). "Efficient Estimation of Word Representations in Vector Space"

2. **FastText:**
   - Bojanowski, P., et al. (2017). "Enriching Word Vectors with Subword Information"

3. **BERT:**
   - Devlin, J., et al. (2019). "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"

4. **Spam Detection:**
   - Almeida, T. A., et al. (2011). "Spam Filtering: How the Dimensionality Reduction Affects the Accuracy of Naive Bayes Classifiers"

5. **Fairness in ML:**
   - Mehrabi, N., et al. (2021). "A Survey on Bias and Fairness in Machine Learning"

---

## üìû Contacto

Para preguntas sobre el proyecto:
- **Repositorio:** [github.com/LhiaHC/Proyecto-IA-2025-2](https://github.com/LhiaHC/Proyecto-IA-2025-2)
- **Issues:** [github.com/LhiaHC/Proyecto-IA-2025-2/issues](https://github.com/LhiaHC/Proyecto-IA-2025-2/issues)

---

## üìÑ Licencia

Este proyecto es de c√≥digo abierto bajo licencia MIT. Ver archivo `LICENSE` para detalles.

---

**√öltima actualizaci√≥n:** 2025-01-23
